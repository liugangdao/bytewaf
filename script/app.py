import time
import numpy as np
import onnxruntime as ort
from fastapi import FastAPI
from pydantic import BaseModel
import tiktoken
from typing import List
import logging

# è®¾ç½®æ—¥å¿—æ ¼å¼å’Œçº§åˆ«
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(name)s: %(message)s",
    handlers=[
        logging.StreamHandler(),  # æŽ§åˆ¶å°è¾“å‡º
        # logging.FileHandler("app.log")  # å¯é€‰ï¼šå†™å…¥æ–‡ä»¶
    ],
)

logger = logging.getLogger("onnx_service")

# åˆå§‹åŒ– FastAPI åº”ç”¨
app = FastAPI()

# åŠ è½½ ONNX æ¨¡åž‹
session = ort.InferenceSession(
    "model_save/model.onnx", providers=["CUDAExecutionProvider"]
)

# åŠ è½½ tokenizer
tokenizer = tiktoken.get_encoding("cl100k_base")


# å®šä¹‰è¾“å…¥æ•°æ®æ ¼å¼
class InputData(BaseModel):
    texts: List[str]
    max_len: int


# åˆ›å»ºé¢„æµ‹æŽ¥å£
@app.post("/detect")
def predict(data: InputData):
    texts = data.texts
    max_len = data.max_len
    # å¯¹è¾“å…¥æ–‡æœ¬è¿›è¡Œç¼–ç 
    all_tokens = []
    # for t in text:
    #     tokens = tokenizer._encode_bytes(t)
    #     all_tokens.append(tokens[:max_len] + [0] * (max_len - len(tokens)))
    start = time.time()
    all_tokens = tokenizer.encode_batch(texts)
    for i in range(len(all_tokens)):
        all_tokens[i] = all_tokens[i][:max_len] + [0] * (max_len - len(all_tokens[i]))

    # è½¬æ¢ä¸º numpy æ•°ç»„
    input_tensor = np.array(all_tokens, dtype=np.int64)
    # print(input_tensor.shape)
    # æ‰§è¡Œæ‰¹é‡æŽ¨ç†

    outputs = session.run(None, {"input": input_tensor})
    logger.info("æŽ¨ç†è€—æ—¶ï¼š", time.time() - start)
    # èŽ·å–åˆ†æ•°å’Œæ ‡ç­¾
    # print(outputs)
    scores = outputs[0].squeeze(axis=1)  # shape: (batch_size,) ä¸€ç»´
    labels = np.where(scores > 0.5, "æ”»å‡» ðŸš¨", "æ­£å¸¸ âœ…")

    results = [
        {"text": text, "score": float(score), "label": label}
        for text, score, label in zip(data.texts, scores, labels)
    ]

    # æ‰¾åˆ°åˆ†æ•°æœ€å¤§çš„ç»“æžœ
    max_idx = np.argmax(scores)
    max_result = results[max_idx]

    return {
        "max_score": max_result["score"],
        "label": max_result["label"],
        "text": max_result["text"],
    }


if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="0.0.0.0", port=5555, workers=8)
